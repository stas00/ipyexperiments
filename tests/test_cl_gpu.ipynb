{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CellLogger subsystem\n",
    "\n",
    "This test tests the CellLogger subsystem, accessible via `exp.cl` once one of the `IPyExperiments` subclasses has been initiated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test specifics\n",
    "\n",
    "Since we need to validate the the output, we have to capture it first. The way jupyter is setup, is that in once cell you set up a capture with `%%capture` magick and then in the next cell you can analyze it. That's why each test group has two cells, the first one doing the action to be tested and the following one doing the validatations.\n",
    "\n",
    "Moreover, the output of this test becomes confusing because the capture mechanism somehow messes things up which leads to re-running the `post_run_cell` callback of the CellLogger subsystem again - as a result you get a bogus output with 0's regardless of the code being run. It doesn't interfere with the testing, but it does interfere with things like `.data` which gets reset because of that, showing invalid information - therefore we can only test `.data` w/o capturing the cell's output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyexperiments import *\n",
    "from utils.text import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipyexperiments.cell_logger.CellLogger object at 0x7f13f82340a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.004\n",
      "･ CPU:          0          0      1,591 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "#if 'exp' in locals(): exp.cl.stop() # helps debug\n",
    "exp1 = IPyExperimentsPytorch(exp_enable=False)\n",
    "exp1.cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.032\n",
      "･ CPU:        128          0      1,719 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.015\n",
      "| ･ CPU:        128          0      1,719 MB |\n",
      "| ･ GPU:          0          0        537 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.002\n",
      "･ CPU:       -127          0      1,591 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_strings(output)\n",
    "check_report_cpu(output, consumed_expected=128, peaked_expected=0, abs_tol=2)\n",
    "\n",
    "# cleanup\n",
    "del cpu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.018\n",
      "･ CPU:          0          0      1,591 MB |\n",
      "･ GPU:        256          0        793 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "gpu1 = consume_gpu_ram_256mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.000\n",
      "| ･ CPU:          0          0      1,591 MB |\n",
      "| ･ GPU:        256          0        793 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.037\n",
      "･ CPU:          0          0      1,591 MB |\n",
      "･ GPU:       -256          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_strings(output)\n",
    "check_report_gpu(output, consumed_expected=256, peaked_expected=0, abs_tol=0)\n",
    "\n",
    "# cleanup\n",
    "del gpu1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume/release leading to positive peak numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.047\n",
      "･ CPU:        128        127      1,720 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test peak measurement\n",
    "# here we consume 256MB of RAM and release 128MB \n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_peak_memory_usage'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.028\n",
      "| ･ CPU:        128        127      1,720 MB |\n",
      "| ･ GPU:          0          0        537 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.002\n",
      "･ CPU:       -127          0      1,592 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_peak_memory_usage\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_cpu(output, consumed_expected=128, peaked_expected=128, abs_tol=2)\n",
    "\n",
    "# cleanup\n",
    "del cpu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.020\n",
      "･ CPU:          0          0      1,592 MB |\n",
      "･ GPU:        256        256        793 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test peak measurement\n",
    "\n",
    "# here we consume 512MB of RAM and release 256MB\n",
    "# testing: Consumed 256, Peaked 256\n",
    "gpu1 = consume_gpu_ram_256mb()\n",
    "gpu2 = consume_gpu_ram_256mb()\n",
    "\n",
    "del gpu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_peak_memory_usage'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.001\n",
      "| ･ CPU:          0          0      1,592 MB |\n",
      "| ･ GPU:        256        256        793 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.001\n",
      "･ CPU:          0          0      1,592 MB |\n",
      "･ GPU:       -256          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_peak_memory_usage\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_gpu(output, consumed_expected=256, peaked_expected=256, abs_tol=2)\n",
    "\n",
    "# cleanup\n",
    "del gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .data accessor validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.148\n",
      "･ CPU:        128        127      1,720 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "# no capture! breaks .data since it re-runs the post_run_cell, again, resetting .data\n",
    "# here we consume 256MB of RAM and release 128MB - so that we can test peak measurement\n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_data_accessor'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134225920\n",
      "134021120\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.025\n",
      "･ CPU:       -127          0      1,592 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_data_accessor\"\"\"\n",
    "cpu_mem   = exp1.cl.data.cpu\n",
    "gpu_mem   = exp1.cl.data.gpu\n",
    "time_data = exp1.cl.data.time\n",
    "\n",
    "check_match(consumed_reported=b2mb(cpu_mem.used_delta), peaked_reported=b2mb(cpu_mem.peaked_delta), \n",
    "            consumed_expected=128,                      peaked_expected=128,  abs_tol=1)\n",
    "\n",
    "# cleanup\n",
    "del cpu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.086\n",
      "･ CPU:          0          0      1,592 MB |\n",
      "･ GPU:        256        256        793 MB |\n"
     ]
    }
   ],
   "source": [
    "# no capture! breaks .data since it re-runs the post_run_cell, again, resetting .data\n",
    "\n",
    "# here we consume 512MB of RAM and release 256MB - so that we can test peak measurement\n",
    "# testing: Consumed 256, Peaked 256\n",
    "gpu1 = consume_gpu_ram_256mb()\n",
    "gpu2 = consume_gpu_ram_256mb()\n",
    "## Consume/Release Positive Peak\n",
    "del gpu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_data_accessor'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268435456\n",
      "268435456\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.065\n",
      "･ CPU:          0          0      1,592 MB |\n",
      "･ GPU:       -256          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_data_accessor\"\"\"\n",
    "cpu_mem   = exp1.cl.data.cpu\n",
    "gpu_mem   = exp1.cl.data.gpu\n",
    "time_data = exp1.cl.data.time\n",
    "\n",
    "check_match(consumed_reported=b2mb(gpu_mem.used_delta), peaked_reported=b2mb(gpu_mem.peaked_delta), \n",
    "            consumed_expected=256,                      peaked_expected=256, abs_tol=1)\n",
    "\n",
    "# cleanup\n",
    "del gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_stop'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.097\n",
      "･ CPU:          0          0      1,592 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_stop\"\"\"\n",
    "exp1.cl.stop()\n",
    "#check that no output appears after this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No captured output\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "assert output == \"\", \"there should be no output as logger has been stopped\"\n",
    "\n",
    "# cleanup\n",
    "del cpu1\n",
    "del exp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit destroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "locals_unset(['exp10'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.049\n",
      "･ CPU:          0          0      1,592 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test destroy which happens when obj is redefined \n",
    "# this one tests with the exp-system turned on, cl-system turned on\n",
    "# this is a pretty normal situation, considering that someone will be reloading the same cell\n",
    "# do not change this test!\n",
    "exp10 = IPyExperimentsPytorch(exp_enable=True, cl_enable=True)\n",
    "exp10 = IPyExperimentsPytorch(exp_enable=True, cl_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:     Used     Free    Total        Util\n",
      "| CPU:    1,592   90,185  128,697 MB   1.24% \n",
      "| GPU:      537    7,582    8,119 MB   6.61% \n",
      "| \n",
      "| \n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:     Used     Free    Total        Util\n",
      "| CPU:    1,592   90,185  128,697 MB   1.24% \n",
      "| GPU:      537    7,582    8,119 MB   6.61% \n",
      "| \n",
      "| \n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.035\n",
      "| ･ CPU:          0          0      1,592 MB |\n",
      "| ･ GPU:          0          2        537 MB |\n",
      "| \n",
      "| IPyExperimentsPytorch: Finishing\n",
      "| \n",
      "| *** Experiment finished in 00:00:00 (elapsed wallclock time)\n",
      "| \n",
      "| *** Experiment memory:\n",
      "| RAM: Consumed       Reclaimed\n",
      "| CPU:        0        0 MB (100.00%)\n",
      "| GPU:        0        0 MB (100.00%)\n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:     Used     Free    Total        Util\n",
      "| CPU:    1,592   90,185  128,697 MB   1.24% \n",
      "| GPU:      537    7,582    8,119 MB   6.61% \n",
      "| \n",
      "| \n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.032\n",
      "| ･ CPU:          0          0      1,592 MB |\n",
      "| ･ GPU:          0          0        537 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.000\n",
      "･ CPU:          0          0      1,592 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "output = str(output)\n",
    "print_output(output)\n",
    "assert \"Error\" not in output, \"shouldn't fail on auto-destruction\"\n",
    "\n",
    "match = re.findall(r'started', output)\n",
    "assert len(match) == 2, f\"should have started twice, got {len(match)}\"\n",
    "\n",
    "match = re.findall(r'Finishing', output)\n",
    "assert len(match) == 1, f\"should have finished once, got {len(match)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.082\n",
      "･ CPU:          0          0      1,592 MB |\n",
      "･ GPU:          0          0        537 MB |\n",
      "\n",
      "IPyExperimentsPytorch: Finishing\n",
      "\n",
      "*** Experiment finished in 00:00:00 (elapsed wallclock time)\n",
      "\n",
      "*** Newly defined local variables:\n",
      "Deleted: match\n",
      "\n",
      "*** Experiment memory:\n",
      "RAM: Consumed       Reclaimed\n",
      "CPU:        0        0 MB (100.00%)\n",
      "GPU:        0        0 MB (100.00%)\n",
      "\n",
      "*** Current state:\n",
      "RAM:     Used     Free    Total        Util\n",
      "CPU:    1,592   90,185  128,697 MB   1.24% \n",
      "GPU:      537    7,582    8,119 MB   6.61% \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cleanup\n",
    "del exp10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit destroy #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.032\n",
      "･ CPU:          0          0      1,592 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test destroy which happens when obj is redefined \n",
    "# this one tests with the exp-system turned off, cl-system turned on\n",
    "# this is a pretty normal situation, considering that someone will be reloading the same cell\n",
    "# do not change this test!\n",
    "exp11 = IPyExperimentsPytorch(exp_enable=False, cl_enable=True)\n",
    "exp11 = IPyExperimentsPytorch(exp_enable=False, cl_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.033\n",
      "| ･ CPU:          0          0      1,592 MB |\n",
      "| ･ GPU:          0          2        537 MB |\n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.017\n",
      "| ･ CPU:          0          0      1,592 MB |\n",
      "| ･ GPU:          0          0        537 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.000\n",
      "･ CPU:          0          0      1,592 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "output = str(output)\n",
    "print_output(output)\n",
    "assert \"Error\" not in output, \"shouldn't fail on auto-destruction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.085\n",
      "･ CPU:          0          0      1,592 MB |\n",
      "･ GPU:          0          0        537 MB |\n"
     ]
    }
   ],
   "source": [
    "# cleanup\n",
    "del exp11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_random_reset_a'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "\n",
      "CPU: 0/0/1592 MB | GPU: 0/0/537 MB | Time 0:00:00.000 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_random_reset_a\"\"\"\n",
    "# a. baseline - rand is different by default\n",
    "exp12 = IPyExperimentsPytorch(exp_enable=False, cl_set_seed=0, cl_compact=True)\n",
    "rnd1 = np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1592 MB | GPU: 0/0/537 MB | Time 0:00:00.000 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "rnd2 = np.random.random()\n",
    "assert rnd1 != rnd2, f\"values should be different rnd1={rnd1} rnd2={rnd2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1592 MB | GPU: 0/0/537 MB | Time 0:00:00.063 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "del exp12 # cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_random_reset_b'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "\n",
      "CPU: 0/0/1592 MB | GPU: 0/0/537 MB | Time 0:00:00.000 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_random_reset_b\"\"\"\n",
    "# b. now automatically reset the seed on each cell run and except the same rand values\n",
    "exp13 = IPyExperimentsPytorch(exp_enable=False, cl_set_seed=42, cl_compact=True)\n",
    "rnd1 = np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1592 MB | GPU: 0/0/537 MB | Time 0:00:00.042 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "rnd2 = np.random.random()\n",
    "assert rnd1 == rnd2, f\"values should be the same rnd1={rnd1} rnd2={rnd2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1592 MB | GPU: 0/0/537 MB | Time 0:00:00.062 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "del exp13 # cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_random_reset_c'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "\n",
      "CPU: 0/0/1592 MB | GPU: 0/0/537 MB | Time 0:00:00.000 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_random_reset_c\"\"\"\n",
    "# c. now back to non-resetting, should be different rand values again\n",
    "exp14 = IPyExperimentsPytorch(exp_enable=False, cl_set_seed=0, cl_compact=True)\n",
    "rnd1 = np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1592 MB | GPU: 0/0/537 MB | Time 0:00:00.000 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "rnd2 = np.random.random()\n",
    "assert rnd1 != rnd2, f\"values should be again different rnd1={rnd1} rnd2={rnd2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1592 MB | GPU: 0/0/537 MB | Time 0:00:00.086 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "del exp14 # cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript # prevent committing an unsaved notebook\n",
    "IPython.notebook.save_notebook()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "323px",
    "left": "956px",
    "right": "20px",
    "top": "152px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
